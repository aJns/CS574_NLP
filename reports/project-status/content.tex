\section{Introduction}
In this report, the status update of the CS574 NLP project is presented. An overview is given of the progress made since the project proposal four weeks previously. The main work done was to conduct additional literature research, create a dataset, attempt to implement summarisation algorithms and to evaluate them. Based on these results, the project will be rounded off in the remaining two weeks.

\section{Dataset}
A dataset was collected from the internet of ten novels and a play, with at least three summaries each. The books are mainly fictional classics, due to their popularity on summary resources and often the expiration of their copyright. Most of the summaries are sourced from CliffsNotes, SparkNotes and GradeSaver. The books and summaries both vary quite vastly in length. All the documents were saved as or converted to text files, to facilitate consistency and ease of manipulation in Python.

\section{Algorithms}

\section{Evaluation}
Aside from simply reading the summarisation outputs of the algorithm, two quantitative measures were proposed to evaluate them. It must be noted again that the scores are expected to be quite low, because the nature of summarisation leads to very different answers with no objective measure of how "good" they are. 

The nltk.translate.bleu\_score toolkit has a function, corpus\_blue, which can be used for BLEU evaluation. BLEU was originally used for translations, but is now also used to evaluate summarisations and is based on precision scores of n-gram overlaps between documents and references. The corpus\_blue allows for varying weights of 1- to 4-grams, and multiple golden references. 


\section{Results and Discussion}